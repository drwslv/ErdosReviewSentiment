{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "77a64941-dc2f-4d67-9fb6-f40e0f341ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, io\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b0cb142c-6c40-430a-b16f-7a75ca1238b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ae2b2dc-54a7-45e2-8d13-9e3885eeb483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb38df75-0fc4-4b23-9381-4a969adbae25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"I like to party and to do that every day\"\n",
    "tokens = word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3897a542-36fb-4004-8bfe-b54c835c7e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, 'I': 1, 'like': 2, 'to': 3, 'party': 4, 'and': 5, 'do': 6, 'that': 7, 'every': 8, 'day': 9}\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "vocab, index = {}, 1  # start indexing from 1\n",
    "vocab['<pad>'] = 0  # add a padding token\n",
    "for token in tokens:\n",
    "  if token not in vocab:\n",
    "    vocab[token] = index\n",
    "    index += 1\n",
    "vocab_size = len(vocab)\n",
    "print(vocab)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "512df8f1-d517-42f3-8fd1-099b6b0ccd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<pad>', 1: 'I', 2: 'like', 3: 'to', 4: 'party', 5: 'and', 6: 'do', 7: 'that', 8: 'every', 9: 'day'}\n"
     ]
    }
   ],
   "source": [
    "inverse_vocab = {index: token for token, index in vocab.items()}\n",
    "print(inverse_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "811c2f14-d73a-41e1-9f98-1dde75c238e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 3, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_sequence = [vocab[word] for word in tokens]\n",
    "example_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d5828813-6630-4f71-80b2-e85623e4e304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size = 2\n",
    "positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "      example_sequence,\n",
    "      vocabulary_size=vocab_size,\n",
    "      window_size=window_size,\n",
    "      negative_samples=0,\n",
    "      seed=10)\n",
    "len(positive_skip_grams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc517b5d-bfa2-4e37-aed1-969b4c681746",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
